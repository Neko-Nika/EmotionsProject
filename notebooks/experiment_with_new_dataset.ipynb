{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\diploma\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from emotions_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_PATH = \"../\"\n",
    "ORIG_PATH = f\"{CORE_PATH}/emotions\"\n",
    "SAVE_LOGS_PATH = f\"{CORE_PATH}/missclassified/new_dataset/\"\n",
    "SAVE_MODELS_PATH = f\"{CORE_PATH}/models/experiment_with_new_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageFolder(ORIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"test_indices.pickle\", \"rb\") as file:\n",
    "    test_indices = pickle.load(file)\n",
    "print(len(test_indices))\n",
    "\n",
    "test_data = torch.utils.data.Subset(data, test_indices)\n",
    "orig_dataset = EmotionsDataset(\n",
    "    test_data,\n",
    "    transforms=inf_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'contempt': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'joy': 4,\n",
       " 'sadness': 5,\n",
       " 'wonder': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = data.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AffectNetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 23916\n",
       "    Root location: ../AffectNetDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ImageFolder(\"../AffectNetDataset\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'contempt': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'joy': 4,\n",
       " 'sadness': 5,\n",
       " 'wonder': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 5044, 6: 4039, 0: 3218, 3: 3176, 5: 3091, 1: 2871, 2: 2477})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_size = 0.75\n",
    "test_size = 1 - train_size\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(\n",
    "    train, [train_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionsDataset(train_data, train_transforms)\n",
    "test_dataset = EmotionsDataset(test_data, inf_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LR = 0.001\n",
    "EPOCHS = 15\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(train_dataset, BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=len(class_to_idx))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:26<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, train_loss: 1.3938110597942985, val_loss: 1.029560433939002\n",
      "train_f1: 0.4604500891265597, val_f1: 0.5991279776373359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:14<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2, train_loss: 1.1520176940308025, val_loss: 1.036764813199213\n",
      "train_f1: 0.5607731729055259, val_f1: 0.6228579241614001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:19<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3, train_loss: 1.07630830884558, val_loss: 0.9895206841762139\n",
      "train_f1: 0.5860071301247772, val_f1: 0.6278864851725814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:22<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4, train_loss: 1.0165614455135834, val_loss: 0.9264650549611871\n",
      "train_f1: 0.6124108734402852, val_f1: 0.6581186193485659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5, train_loss: 0.9799070142082009, val_loss: 0.9270251702257454\n",
      "train_f1: 0.6317959001782532, val_f1: 0.6569488332523091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6, train_loss: 0.9280679702041021, val_loss: 0.9010205911062776\n",
      "train_f1: 0.6482286096256684, val_f1: 0.6759236752552261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 7, train_loss: 0.8971726019100553, val_loss: 1.000182195518463\n",
      "train_f1: 0.6566399286987522, val_f1: 0.6455092367525523\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 8, train_loss: 0.8744524918771172, val_loss: 0.9380626103454937\n",
      "train_f1: 0.6732954545454546, val_f1: 0.6749969615945551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 9, train_loss: 0.8390786479652849, val_loss: 1.0247710647342156\n",
      "train_f1: 0.6808155080213903, val_f1: 0.6502643412736996\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10, train_loss: 0.8156351278463175, val_loss: 0.9733504022338115\n",
      "train_f1: 0.696078431372549, val_f1: 0.6583009236752552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:11<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11, train_loss: 0.7781896364292107, val_loss: 0.9883801048666084\n",
      "train_f1: 0.7097816399286988, val_f1: 0.6601391589693728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12, train_loss: 0.7563105015649161, val_loss: 1.020820849993333\n",
      "train_f1: 0.7204768270944741, val_f1: 0.6632231404958678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:11<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13, train_loss: 0.7519575080654725, val_loss: 1.0437844484760364\n",
      "train_f1: 0.7174688057040999, val_f1: 0.6698924404472534\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [03:10<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14, train_loss: 0.7130709737215299, val_loss: 1.1483665214451804\n",
      "train_f1: 0.734792780748663, val_f1: 0.6538496596985902\n",
      "\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "loss_train, loss_val = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    \"best_effnetb4_15.pt\",\n",
    "    early_stopping=EarlyStopping(patience=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..//models/experiment_with_new_dataset/best_effnetb4_15.pt'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), f\"{SAVE_MODELS_PATH}/effnetb4_15_train.pt\")\n",
    "shutil.copyfile(\"best_effnetb4_15.pt\", f\"{SAVE_MODELS_PATH}/best_effnetb4_15.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best =  timm.create_model('efficientnet_b4', pretrained=True, num_classes=len(class_to_idx))\n",
    "best.load_state_dict(torch.load(f\"{SAVE_MODELS_PATH}/best_effnetb4_15.pt\"))\n",
    "best.eval()\n",
    "best = best.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6538496596985902\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6759236752552261\n"
     ]
    }
   ],
   "source": [
    "test_model(best, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for i in range(len(orig_dataset)):\n",
    "    img, label = orig_dataset[i][0], orig_dataset[i][1]\n",
    "    img = img.to(device)\n",
    "    \n",
    "    numpy_image = img[None, :]\n",
    "    prediction = best(numpy_image)\n",
    "    predicted = prediction.argmax()\n",
    "    \n",
    "    pred.append(predicted.cpu().item())\n",
    "    actual.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5934959349593496,\n",
       " 'Precision_macro': 0.6263734584742988,\n",
       " 'Precision_micro': 0.5934959349593496,\n",
       " 'Recall_macro': 0.5938919726889651,\n",
       " 'Recall_micro': 0.5934959349593496,\n",
       " 'ROC_AUC': {0: 0.7490170380078637,\n",
       "  1: 0.6219635627530364,\n",
       "  2: 0.7778761061946904,\n",
       "  3: 0.7667832167832168,\n",
       "  4: 0.8674757281553398,\n",
       "  5: 0.74,\n",
       "  6: 0.8190819081908192}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_report(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger emotion\n",
      "Overall images: 14\n",
      "Correctly predicted 8/14\n",
      "\n",
      "contempt emotion\n",
      "Overall images: 19\n",
      "Correctly predicted 5/19\n",
      "\n",
      "disgust emotion\n",
      "Overall images: 10\n",
      "Correctly predicted 6/10\n",
      "\n",
      "fear emotion\n",
      "Overall images: 13\n",
      "Correctly predicted 8/13\n",
      "\n",
      "joy emotion\n",
      "Overall images: 20\n",
      "Correctly predicted 18/20\n",
      "\n",
      "sadness emotion\n",
      "Overall images: 25\n",
      "Correctly predicted 12/25\n",
      "\n",
      "wonder emotion\n",
      "Overall images: 22\n",
      "Correctly predicted 16/22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(actual, pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_indices.pickle\", \"rb\") as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "inf_images = [data.imgs[x][0] for x in test_indices]\n",
    "get_mistaken_images_report(inf_images, actual, pred, \"effnetb4_15\", idx_to_class, SAVE_LOGS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
