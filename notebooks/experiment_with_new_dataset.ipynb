{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from emotions_utils import *\n",
    "import timm\n",
    "\n",
    "from torchvision.models import (\n",
    "    resnet18,\n",
    "    ResNet18_Weights,\n",
    "    resnet50,\n",
    "    ResNet50_Weights,\n",
    "    vgg19_bn,\n",
    "    VGG19_BN_Weights,\n",
    "    alexnet,\n",
    "    AlexNet_Weights,\n",
    "    vit_b_16,\n",
    "    ViT_B_16_Weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_PATH = \"../\"\n",
    "ORIG_PATH = f\"{CORE_PATH}/emotions\"\n",
    "SAVE_LOGS_PATH = f\"{CORE_PATH}/missclassified/new_dataset/\"\n",
    "SAVE_MODELS_PATH = f\"{CORE_PATH}/models/experiment_with_new_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageFolder(ORIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "373\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"test_indices.pickle\", \"rb\") as file:\n",
    "    test_indices = pickle.load(file)\n",
    "with open(\"train_indices.pickle\", \"rb\") as file:\n",
    "    train_indices = pickle.load(file)\n",
    "print(len(test_indices))\n",
    "print(len(train_indices))\n",
    "\n",
    "test_data = torch.utils.data.Subset(data, test_indices)\n",
    "orig_dataset = EmotionsDataset(\n",
    "    test_data,\n",
    "    transforms=inf_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'contempt': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'joy': 4,\n",
       " 'sadness': 5,\n",
       " 'wonder': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = data.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AffectNetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 23916\n",
       "    Root location: ../AffectNetDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ImageFolder(\"../AffectNetDataset\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'contempt': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'joy': 4,\n",
       " 'sadness': 5,\n",
       " 'wonder': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 5044, 6: 4039, 0: 3218, 3: 3176, 5: 3091, 1: 2871, 2: 2477})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_size = 0.75\n",
    "test_size = 1 - train_size\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(\n",
    "    train, [train_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionsDataset(train_data, train_transforms)\n",
    "test_dataset = EmotionsDataset(test_data, inf_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LR = 0.001\n",
    "EPOCHS = 15\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(train_dataset, BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effnet_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=len(class_to_idx))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, loss_val = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    \"best_effnetb4_15.pt\",\n",
    "    early_stopping=EarlyStopping(patience=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..//models/experiment_with_new_dataset/best_effnetb4_15.pt'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), f\"{SAVE_MODELS_PATH}/effnetb4_15_train.pt\")\n",
    "shutil.copyfile(\"best_effnetb4_15.pt\", f\"{SAVE_MODELS_PATH}/best_effnetb4_15.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best =  timm.create_model('efficientnet_b4', pretrained=True, num_classes=len(class_to_idx))\n",
    "best.load_state_dict(torch.load(f\"{SAVE_MODELS_PATH}/best_effnetb4_15.pt\"))\n",
    "best.eval()\n",
    "best = best.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6538496596985902\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for i in range(len(orig_dataset)):\n",
    "    img, label = orig_dataset[i][0], orig_dataset[i][1]\n",
    "    img = img.to(device)\n",
    "    \n",
    "    numpy_image = img[None, :]\n",
    "    prediction = best(numpy_image)\n",
    "    predicted = prediction.argmax()\n",
    "    \n",
    "    pred.append(predicted.cpu().item())\n",
    "    actual.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5934959349593496,\n",
       " 'Precision_macro': 0.6263734584742988,\n",
       " 'Precision_micro': 0.5934959349593496,\n",
       " 'Recall_macro': 0.5938919726889651,\n",
       " 'Recall_micro': 0.5934959349593496,\n",
       " 'ROC_AUC': {0: 0.7490170380078637,\n",
       "  1: 0.6219635627530364,\n",
       "  2: 0.7778761061946904,\n",
       "  3: 0.7667832167832168,\n",
       "  4: 0.8674757281553398,\n",
       "  5: 0.74,\n",
       "  6: 0.8190819081908192}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_report(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger emotion\n",
      "Overall images: 14\n",
      "Correctly predicted 8/14\n",
      "\n",
      "contempt emotion\n",
      "Overall images: 19\n",
      "Correctly predicted 5/19\n",
      "\n",
      "disgust emotion\n",
      "Overall images: 10\n",
      "Correctly predicted 6/10\n",
      "\n",
      "fear emotion\n",
      "Overall images: 13\n",
      "Correctly predicted 8/13\n",
      "\n",
      "joy emotion\n",
      "Overall images: 20\n",
      "Correctly predicted 18/20\n",
      "\n",
      "sadness emotion\n",
      "Overall images: 25\n",
      "Correctly predicted 12/25\n",
      "\n",
      "wonder emotion\n",
      "Overall images: 22\n",
      "Correctly predicted 16/22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(actual, pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_indices.pickle\", \"rb\") as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "inf_images = [data.imgs[x][0] for x in test_indices]\n",
    "get_mistaken_images_report(inf_images, actual, pred, \"effnetb4_15\", idx_to_class, SAVE_LOGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(model.fc.in_features, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(),\n",
    "                           nn.Linear(512, len(class_to_idx)))\n",
    "model.fc = classifier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, loss_val = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    \"best_resnet18_new_data_15.pt\",\n",
    "    early_stopping=EarlyStopping(patience=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for i in range(len(orig_dataset)):\n",
    "    img, label = orig_dataset[i][0], orig_dataset[i][1]\n",
    "    img = img.to(device)\n",
    "    \n",
    "    numpy_image = img[None, :]\n",
    "    prediction = best(numpy_image)\n",
    "    predicted = prediction.argmax()\n",
    "    \n",
    "    pred.append(predicted.cpu().item())\n",
    "    actual.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\diploma_emotions\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.14634146341463414,\n",
       " 'Precision_macro': 0.2776759530791789,\n",
       " 'Precision_micro': 0.14634146341463414,\n",
       " 'Recall_macro': 0.1301033552913252,\n",
       " 'Recall_micro': 0.14634146341463414,\n",
       " 'ROC_AUC': {0: 0.5190039318479684,\n",
       "  1: 0.4782388663967611,\n",
       "  2: 0.5,\n",
       "  3: 0.5384615384615384,\n",
       "  4: 0.45218446601941753,\n",
       "  5: 0.43469387755102035,\n",
       "  6: 0.5177767776777678}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_report(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger emotion\n",
      "Overall images: 14\n",
      "Correctly predicted 4/14\n",
      "\n",
      "contempt emotion\n",
      "Overall images: 19\n",
      "Correctly predicted 1/19\n",
      "\n",
      "disgust emotion\n",
      "Overall images: 10\n",
      "Correctly predicted 0/10\n",
      "\n",
      "fear emotion\n",
      "Overall images: 13\n",
      "Correctly predicted 1/13\n",
      "\n",
      "joy emotion\n",
      "Overall images: 20\n",
      "Correctly predicted 1/20\n",
      "\n",
      "sadness emotion\n",
      "Overall images: 25\n",
      "Correctly predicted 10/25\n",
      "\n",
      "wonder emotion\n",
      "Overall images: 22\n",
      "Correctly predicted 1/22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(actual, pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(model.fc.in_features, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(),\n",
    "                           nn.Linear(512, len(class_to_idx)))\n",
    "model.fc = classifier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, loss_val = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    \"best_resnet50_new_data_15.pt\",\n",
    "    early_stopping=EarlyStopping(patience=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for i in range(len(orig_dataset)):\n",
    "    img, label = orig_dataset[i][0], orig_dataset[i][1]\n",
    "    img = img.to(device)\n",
    "    \n",
    "    numpy_image = img[None, :]\n",
    "    prediction = best(numpy_image)\n",
    "    predicted = prediction.argmax()\n",
    "    \n",
    "    pred.append(predicted.cpu().item())\n",
    "    actual.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.21951219512195122,\n",
       " 'Precision_macro': 0.2694493810283284,\n",
       " 'Precision_micro': 0.21951219512195122,\n",
       " 'Recall_macro': 0.22146853146853146,\n",
       " 'Recall_micro': 0.21951219512195122,\n",
       " 'ROC_AUC': {0: 0.4862385321100917,\n",
       "  1: 0.49038461538461536,\n",
       "  2: 0.55,\n",
       "  3: 0.5737762237762238,\n",
       "  4: 0.7036407766990291,\n",
       "  5: 0.49408163265306126,\n",
       "  6: 0.5216021602160216}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_report(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger emotion\n",
      "Overall images: 14\n",
      "Correctly predicted 0/14\n",
      "\n",
      "contempt emotion\n",
      "Overall images: 19\n",
      "Correctly predicted 0/19\n",
      "\n",
      "disgust emotion\n",
      "Overall images: 10\n",
      "Correctly predicted 1/10\n",
      "\n",
      "fear emotion\n",
      "Overall images: 13\n",
      "Correctly predicted 7/13\n",
      "\n",
      "joy emotion\n",
      "Overall images: 20\n",
      "Correctly predicted 13/20\n",
      "\n",
      "sadness emotion\n",
      "Overall images: 25\n",
      "Correctly predicted 2/25\n",
      "\n",
      "wonder emotion\n",
      "Overall images: 22\n",
      "Correctly predicted 4/22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(actual, pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg19_bn(weights=VGG19_BN_Weights.DEFAULT)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[6] = nn.Sequential(nn.Linear(model.classifier[6].in_features, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(),\n",
    "                           nn.Linear(512, len(class_to_idx)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, loss_val = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    \"best_vgg19_new_data_15.pt\",\n",
    "    early_stopping=EarlyStopping(patience=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for i in range(len(orig_dataset)):\n",
    "    img, label = orig_dataset[i][0], orig_dataset[i][1]\n",
    "    img = img.to(device)\n",
    "    \n",
    "    numpy_image = img[None, :]\n",
    "    prediction = best(numpy_image)\n",
    "    predicted = prediction.argmax()\n",
    "    \n",
    "    pred.append(predicted.cpu().item())\n",
    "    actual.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.2682926829268293,\n",
       " 'Precision_macro': 0.2984787550271027,\n",
       " 'Precision_micro': 0.2682926829268293,\n",
       " 'Recall_macro': 0.24364635364635362,\n",
       " 'Recall_micro': 0.2682926829268293,\n",
       " 'ROC_AUC': {0: 0.4908256880733945,\n",
       "  1: 0.4855769230769231,\n",
       "  2: 0.49557522123893805,\n",
       "  3: 0.6695804195804196,\n",
       "  4: 0.6497572815533981,\n",
       "  5: 0.5787755102040816,\n",
       "  6: 0.5454545454545454}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_report(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger emotion\n",
      "Overall images: 14\n",
      "Correctly predicted 0/14\n",
      "\n",
      "contempt emotion\n",
      "Overall images: 19\n",
      "Correctly predicted 0/19\n",
      "\n",
      "disgust emotion\n",
      "Overall images: 10\n",
      "Correctly predicted 0/10\n",
      "\n",
      "fear emotion\n",
      "Overall images: 13\n",
      "Correctly predicted 5/13\n",
      "\n",
      "joy emotion\n",
      "Overall images: 20\n",
      "Correctly predicted 19/20\n",
      "\n",
      "sadness emotion\n",
      "Overall images: 25\n",
      "Correctly predicted 7/25\n",
      "\n",
      "wonder emotion\n",
      "Overall images: 22\n",
      "Correctly predicted 2/22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(actual, pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier._modules['6'] = nn.Sequential(\n",
    "    nn.Linear(model.classifier._modules['6'].in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(512, len(class_to_idx)),\n",
    ")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, loss_val = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    \"best_alexnet_new_data_15.pt\",\n",
    "    early_stopping=EarlyStopping(patience=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for i in range(len(orig_dataset)):\n",
    "    img, label = orig_dataset[i][0], orig_dataset[i][1]\n",
    "    img = img.to(device)\n",
    "    \n",
    "    numpy_image = img[None, :]\n",
    "    prediction = best(numpy_image)\n",
    "    predicted = prediction.argmax()\n",
    "    \n",
    "    pred.append(predicted.cpu().item())\n",
    "    actual.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3252032520325203,\n",
       " 'Precision_macro': 0.3965296049803092,\n",
       " 'Precision_micro': 0.3252032520325203,\n",
       " 'Recall_macro': 0.3202085132912201,\n",
       " 'Recall_micro': 0.3252032520325203,\n",
       " 'ROC_AUC': {0: 0.601572739187418,\n",
       "  1: 0.6123481781376517,\n",
       "  2: 0.5867256637168141,\n",
       "  3: 0.56993006993007,\n",
       "  4: 0.7524271844660194,\n",
       "  5: 0.529795918367347,\n",
       "  6: 0.5711071107110711}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_report(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger emotion\n",
      "Overall images: 14\n",
      "Correctly predicted 4/14\n",
      "\n",
      "contempt emotion\n",
      "Overall images: 19\n",
      "Correctly predicted 5/19\n",
      "\n",
      "disgust emotion\n",
      "Overall images: 10\n",
      "Correctly predicted 2/10\n",
      "\n",
      "fear emotion\n",
      "Overall images: 13\n",
      "Correctly predicted 3/13\n",
      "\n",
      "joy emotion\n",
      "Overall images: 20\n",
      "Correctly predicted 20/20\n",
      "\n",
      "sadness emotion\n",
      "Overall images: 25\n",
      "Correctly predicted 2/25\n",
      "\n",
      "wonder emotion\n",
      "Overall images: 22\n",
      "Correctly predicted 4/22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(actual, pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(model.heads[0].in_features, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(),\n",
    "                           nn.Linear(512, len(class_to_idx)))\n",
    "model.heads = classifier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, loss_val = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    \"best_vit16_new_data_15.pt\",\n",
    "    early_stopping=EarlyStopping(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for i in range(len(orig_dataset)):\n",
    "    img, label = orig_dataset[i][0], orig_dataset[i][1]\n",
    "    img = img.to(device)\n",
    "    \n",
    "    numpy_image = img[None, :]\n",
    "    prediction = best(numpy_image)\n",
    "    predicted = prediction.argmax()\n",
    "    \n",
    "    pred.append(predicted.cpu().item())\n",
    "    actual.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3983739837398374,\n",
       " 'Precision_macro': 0.3591971916971917,\n",
       " 'Precision_micro': 0.3983739837398374,\n",
       " 'Recall_macro': 0.36481060293090367,\n",
       " 'Recall_micro': 0.3983739837398374,\n",
       " 'ROC_AUC': {0: 0.5576671035386631,\n",
       "  1: 0.707995951417004,\n",
       "  2: 0.5146017699115045,\n",
       "  3: 0.56993006993007,\n",
       "  4: 0.8133495145631068,\n",
       "  5: 0.49367346938775514,\n",
       "  6: 0.7637263726372637}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_report(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger emotion\n",
      "Overall images: 14\n",
      "Correctly predicted 2/14\n",
      "\n",
      "contempt emotion\n",
      "Overall images: 19\n",
      "Correctly predicted 9/19\n",
      "\n",
      "disgust emotion\n",
      "Overall images: 10\n",
      "Correctly predicted 1/10\n",
      "\n",
      "fear emotion\n",
      "Overall images: 13\n",
      "Correctly predicted 3/13\n",
      "\n",
      "joy emotion\n",
      "Overall images: 20\n",
      "Correctly predicted 17/20\n",
      "\n",
      "sadness emotion\n",
      "Overall images: 25\n",
      "Correctly predicted 3/25\n",
      "\n",
      "wonder emotion\n",
      "Overall images: 22\n",
      "Correctly predicted 14/22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(actual, pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
